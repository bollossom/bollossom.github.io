---
title: "SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural Network"
collection: preprint
permalink: /publications/GAC
excerpt: "Spiking neural networks (SNNs) have demonstrated the capability to achieve comparable performance to deep neural networks (DNNs) in both visual and linguistic domains while offering the advantages of improved energy efficiency and adherence to biological plausibility. However, the extension of such single-modality SNNs into the realm of multimodal scenarios remains an unexplored territory. Drawing inspiration from the concept of contrastive language-image pre-training (CLIP), we introduce a novel framework, named SpikeCLIP, to address the gap between two modalities within the context of spike-based computing through a two-step recipe involving 'Alignment Pre-training + Dual-Loss Fine-tuning'. Extensive experiments demonstrate that SNNs achieve comparable results to their DNN counterparts while significantly reducing energy consumption across a variety of datasets commonly used for multimodal model evaluation. Furthermore, SpikeCLIP maintains robust performance in image classification tasks that involve class labels not predefined within specific categories."
date: 2023-10-12
venue: 'arxiv'
paperurl: 'https://arxiv.org/pdf/2310.06488.pdf'
citation: 'Li T, Liu W, Lv C, et al. SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural Network[J]. arXiv preprint arXiv:2310.06488, 2023.'
---

[Download paper here](https://arxiv.org/pdf/2310.06488.pdf)
